{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datawhale 零基础入门CV赛事-Task3 字符识别模型     \n",
    "     \n",
    "在前面的章节，我们讲解了赛题的背景知识和赛题数据的读取。本章开始构建一个字符识别模型，基于对赛题理解本章将构建一个定长多字符分类模型。\n",
    "     \n",
    "## 3 字符识别模型\n",
    "      \n",
    "本章将会讲解卷积神经网络（Convolutional Neural Network, CNN）的常见层，并从头搭建一个字符识别模型。     \n",
    "     \n",
    "### 3.1 学习目标     \n",
    "- 学习CNN基础和原理      \n",
    "- 使用Pytorch框架构建CNN模型，并完成训练      \n",
    "      \n",
    "### 3.2 CNN介绍      \n",
    "卷积神经网络（简称CNN）是一类特殊的人工神经网络，是深度学习中重要的一个分支。CNN在很多领域都表现优异，精度和速度比传统计算学习算法高很多。特别是在计算机视觉领域，CNN是解决图像分类、图像检索、物体检测和语义分割的主流模型。      \n",
    "          \n",
    "CNN每一层由众多的卷积核组成，每个卷积核对输入的像素进行卷积操作，得到下一次的输入。随着网络层的增加卷积核会逐渐扩大感受野，并缩减图像的尺寸。        \n",
    "             \n",
    "  ![IMG](卷积.png)    \n",
    "                  \n",
    "CNN是一种层次模型，输入的是原始的像素数据。CNN通过卷积（convolution）、池化（pooling）、非线性激活函数（non-linear activation function）和全连接层（fully connected layer）构成。      \n",
    "\n",
    "如下图所示为LeNet网络结构，是非常经典的字符识别模型。两个卷积层，两个池化层，两个全连接层组成。卷积核都是5×5，stride=1，池化层使用最大池化。    \n",
    "     \n",
    " ![IMG](Le_CNN.png)       \n",
    "           \n",
    "通过多次卷积和池化，CNN的最后一层将输入的图像像素映射为具体的输出。如在分类任务中会转换为不同类别的概率输出，然后计算真实标签与CNN模型的预测结果的差异，并通过反向传播更新每层的参数，并在更新完成后再次前向传播，如此反复直到训练完成 。\n",
    "         \n",
    "与传统机器学习模型相比，CNN具有一种端到端（End to End）的思路。在CNN训练的过程中是直接从图像像素到最终的输出，并不涉及到具体的特征提取和构建模型的过程，也不需要人工的参与。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch构建CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "# 定义模型\n",
    "class SVHN_Model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SVHN_Model1, self).__init__()\n",
    "        # CNN提取特征模块\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2)),\n",
    "            nn.ReLU(),  \n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2)),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        # \n",
    "        self.fc1 = nn.Linear(32*3*7, 11)\n",
    "        self.fc2 = nn.Linear(32*3*7, 11)\n",
    "        self.fc3 = nn.Linear(32*3*7, 11)\n",
    "        self.fc4 = nn.Linear(32*3*7, 11)\n",
    "        self.fc5 = nn.Linear(32*3*7, 11)\n",
    "        self.fc6 = nn.Linear(32*3*7, 11)\n",
    "    \n",
    "    def forward(self, img):        \n",
    "        feat = self.cnn(img)\n",
    "        feat = feat.view(feat.shape[0], -1)\n",
    "        c1 = self.fc1(feat)\n",
    "        c2 = self.fc2(feat)\n",
    "        c3 = self.fc3(feat)\n",
    "        c4 = self.fc4(feat)\n",
    "        c5 = self.fc5(feat)\n",
    "        c6 = self.fc6(feat)\n",
    "        return c1, c2, c3, c4, c5, c6\n",
    "    \n",
    "model = SVHN_Model1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 优化器\n",
    "optimizer = torch.optim.Adam(model.parameters(), 0.005)\n",
    "\n",
    "loss_plot, c0_plot = [], []\n",
    "# 迭代10个Epoch\n",
    "for epoch in range(10):\n",
    "    for data in train_loader:\n",
    "        c0, c1, c2, c3, c4, c5 = model(data[0])\n",
    "        loss = criterion(c0, data[1][:, 0]) + \\\n",
    "                criterion(c1, data[1][:, 1]) + \\\n",
    "                criterion(c2, data[1][:, 2]) + \\\n",
    "                criterion(c3, data[1][:, 3]) + \\\n",
    "                criterion(c4, data[1][:, 4]) + \\\n",
    "                criterion(c5, data[1][:, 5])\n",
    "        loss /= 6\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_plot.append(loss.item())\n",
    "        c0_plot.append((c0.argmax(1) == data[1][:, 0]).sum().item()*1.0 / c0.shape[0])\n",
    "        \n",
    "    print(epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
